{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport os\nimport matplotlib.pyplot as plt\nfrom PIL import Image\nimport cv2\nimport random\nimport tensorflow as tf\nfrom tensorflow.keras.optimizers import RMSprop\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.utils import to_categorical\nfrom tensorflow.keras.layers import Input, Dense, Conv2D, MaxPooling2D, UpSampling2D, Flatten, Reshape, Conv2DTranspose, ZeroPadding2D, Cropping2D\nfrom tensorflow.keras.models import Model\nfrom shutil import copyfile, rmtree\nfrom timeit import default_timer as timer","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Вспомогательная функция для доступа к файлам относительно корня директория с данными.\nINPUT_ROOT = \"../input/gtsrb-german-traffic-sign\"\ndef from_input(path):\n    return os.path.join(INPUT_ROOT, path)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"# Загружаем таблицу с данными о данных.\ntrain_info = pd.read_csv(from_input(\"Train.csv\"))\ntrain_info.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Посмотрим как выглядят наши данные.\ntrain_info.describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# сколько примеров в каждом из классов\ntrain_info.groupby('ClassId')['ClassId'].count()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_info =  pd.read_csv(from_input(\"Test.csv\"))\ntest_info.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_info.describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# сколько примеров в каждом из классов\ntest_info.groupby('ClassId')['ClassId'].count()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%matplotlib inline\n\nimport matplotlib.image as mpimg\nimport matplotlib.pyplot as plt\n\n# Показываем изображения в сетке 6х8.\nnrows = 8\nncols = 6\n\npic_offset = 0 # Чтобы итерировать по изображениям каждый раз когда запустим код ниже.","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def show_images(offset):\n    fig = plt.gcf()\n    fig.set_size_inches(ncols*3, nrows*3)\n\n    for i in range(43):\n        # subplot индексы начинаются с 1\n        sp = plt.subplot(nrows, ncols, i + 1)\n        sp.axis('Off')\n        subdir = os.path.join(from_input('train'), str(i))\n        files = os.listdir(subdir)\n        img_path = os.path.join(subdir, files[offset % len(files)])\n        img = mpimg.imread(img_path)\n        #print(img.shape)\n        plt.imshow(img)\n\n    plt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"show_images(pic_offset)\npic_offset += 1","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Загрузка и подготовка данных:"},{"metadata":{"trusted":true},"cell_type":"code","source":"TARGET_SIZE = (38, 38) # изображения будут изменены до этого размера\nFLATTEN_SIZE = TARGET_SIZE[0] * TARGET_SIZE[1] * 3\nBATCH_SIZE=300","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"paths = train_info['Path'].values\ny_train = train_info['ClassId'].values\n\nindices = np.arange(y_train.shape[0])\nrandgen = random.Random(62)\nrandgen.shuffle(indices)\n\npaths = paths[indices]\ny_train = y_train[indices]\ny_train = to_categorical(y_train, 43)\n\ndata=[]\n\nfor i, f in enumerate(paths):\n    print('\\rLoading data {0:.1f}%...'.format((i / len(paths)) * 100), end = '\\r')\n    image = Image.open(os.path.join(from_input('train'), f.replace('Train/', '')))\n    resized_image = image.resize(TARGET_SIZE)\n    data.append(np.array(resized_image))\n\nX_train = np.array(data).astype('float32') / 255.0\n\nprint('Data loaded.              ')\n\ntrain_datagen = ImageDataGenerator()\ntrain_generator = train_datagen.flow(X_train,\n                                    y_train,\n                                    batch_size=BATCH_SIZE,\n                                    shuffle=True,\n                                    seed=17)\n\nae_datagen = ImageDataGenerator()\nae_generator = ae_datagen.flow(X_train,\n                                X_train,\n                                batch_size=BATCH_SIZE,\n                                shuffle=True,\n                                seed=11)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"paths = test_info['Path'].values\ny_test = test_info['ClassId'].values\ny_test = to_categorical(y_test, 43)\n\ndata=[]\n\nfor i, f in enumerate(paths):\n    print('\\rLoading data {0:.1f}%...'.format((i / len(paths)) * 100), end = '\\r')\n    image = Image.open(os.path.join(from_input('test'), f.replace('Test/', '')))\n    resized_image = image.resize(TARGET_SIZE)\n    data.append(np.array(resized_image))\n\nprint('Data loaded.              ')\n\nX_test = np.array(data).astype('float32') / 255.0 \n\ntest_datagen = ImageDataGenerator()\ntest_generator = test_datagen.flow(X_test,\n                                    y_test,\n                                    batch_size=BATCH_SIZE,\n                                    shuffle=False,\n                                    seed=17)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Некоторые вспомогательные функции:"},{"metadata":{"trusted":true},"cell_type":"code","source":"def plot(history, plot_acc = True):\n    %matplotlib inline\n\n    import matplotlib.image  as mpimg\n    import matplotlib.pyplot as plt\n\n    \n    loss=history.history['loss']\n    epochs=range(len(loss))\n    plt.figure()\n    plt.plot(epochs, loss, 'r', \"Training Loss\")\n    plt.xlabel('Epoch')\n    plt.title('Training loss')\n\n    if plot_acc:\n        acc=history.history['acc']\n        plt.figure()\n        plt.plot(epochs, acc, 'r', \"Training Accuracy\")\n        plt.title('Training accuracy')\n        plt.xlabel('Epoch')\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def show_layers(model):\n    print('Name\\tOutput shape\\tActivation\\tInitializer')\n    for l in model.layers:\n        print('{0}({1})\\t{2}\\t{3}\\t{4}'\n            .format(l.name,\n              l.__class__.__name__,\n              l.output_shape,\n              l.activation.__name__ if hasattr(l, 'activation') else '<none>',\n              l.kernel_initializer.__class__.__name__ if hasattr(l, 'kernel_initializer') else '<none>'))\n\n\ndef custom_summary(model):\n    model.summary()\n    show_layers(model)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"VERBOSE=1","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def train_model(model, kernel_initializer, optimizer, epochs):\n    model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])\n\n    start_time = timer()\n    history = model.fit_generator(train_generator,\n                        epochs=epochs,\n                        verbose=VERBOSE,\n                        callbacks=[tf.keras.callbacks.EarlyStopping(monitor='acc', min_delta=0.0001, patience=2)],\n                        steps_per_epoch= round(X_train.shape[0] / BATCH_SIZE))\n    end_time = timer()\n    \n    custom_summary(model)\n    print('==============================')\n    print('Initializer: ', kernel_initializer)\n    print('Optimizer: ', optimizer.__class__.__name__)\n    print('Learning rate: ', optimizer.get_config()['learning_rate'])\n    print('Epochs: ', epochs)\n    print('==============================')\n    print('Trained in {0:.2f} minutes'.format((end_time - start_time) / 60))\n    \n    acc=history.history['acc'][-1]\n    test_acc = model.evaluate_generator(test_generator)[1]\n    \n    print('Results at the end of training: acc={1:.02f}%, test_acc={2:.02f}%'\n          .format(i, acc*100, test_acc*100))\n\n    plot(history)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def train_autoencoder(ae_model, kernel_initializer, optimizer, epochs):\n    ae_model.compile(loss='mean_squared_error', optimizer = optimizer)\n    \n    start_time = timer()\n    history = ae_model.fit_generator(ae_generator,\n                        epochs=epochs,\n                        verbose=VERBOSE,\n                        steps_per_epoch= round(X_train.shape[0] / BATCH_SIZE))\n    end_time = timer()\n    \n    custom_summary(ae_model)\n    print('==============================')\n    print('Initializer: ', kernel_initializer)\n    print('Optimizer: ', optimizer.__class__.__name__)\n    print('Learning rate: ', optimizer.get_config()['learning_rate'])\n    print('Epochs: ', epochs)\n    print('==============================')\n    print('Trained in {0:.2f} minutes'.format((end_time - start_time) / 60))\n    plot(history, plot_acc = False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def train_ae_stack_layer(ae_model, kernel_initializer, optimizer, epochs, data):\n    ae_model.compile(loss='mean_squared_error', optimizer = optimizer)\n    \n    start_time = timer()\n    history = ae_model.fit(data,\n                           data,\n                            epochs=epochs,\n                            verbose=VERBOSE,\n                            steps_per_epoch= round(X_train.shape[0] / BATCH_SIZE))\n    end_time = timer()\n    \n    print('==============================')\n    print('Initializer: ', kernel_initializer)\n    print('Optimizer: ', optimizer.__class__.__name__)\n    print('Learning rate: ', optimizer.get_config()['learning_rate'])\n    print('Epochs: ', epochs)\n    print('==============================')\n    print('Trained in {0:.2f} minutes'.format((end_time - start_time) / 60))\n    plot(history, plot_acc = False)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Тренируем стек автокодировщиков - полносвязных:"},{"metadata":{},"cell_type":"markdown","source":"Для сравнения тренируем и тестируем сеть без предварительной настройки параметров."},{"metadata":{"trusted":true},"cell_type":"code","source":"kernel_initializer='glorot_uniform'\noptimizer=Adam(learning_rate=0.0001)\nepochs=20\n\nmodel = tf.keras.models.Sequential([\n    Flatten(input_shape=TARGET_SIZE + (3,)),\n    Dense(256, activation='tanh', kernel_initializer=kernel_initializer),\n    Dense(128, activation='tanh', kernel_initializer=kernel_initializer),\n    Dense(43, activation='softmax')\n])\n\ntrain_model(model, kernel_initializer, optimizer, epochs)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Тренируем первый слой автокодировщикa:"},{"metadata":{"trusted":true},"cell_type":"code","source":"flatX = X_train.reshape((X_train.shape[0], FLATTEN_SIZE))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"kernel_initializer='glorot_uniform'\noptimizer=Adam(learning_rate=0.0001)\nepochs = 20\n\ninput1 = Input(shape=(FLATTEN_SIZE,))\nfirst_dense_l = Dense(256, activation='tanh', kernel_initializer=kernel_initializer)\nfirst_dense = first_dense_l(input1)\nreverse_first_dense_l = Dense(FLATTEN_SIZE, activation='tanh', kernel_initializer=kernel_initializer)\noutput = reverse_first_dense_l(first_dense)\n\nae_model = Model(input1, output)\n\ntrain_ae_stack_layer(ae_model, kernel_initializer, optimizer, epochs, flatX)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Тренируем второй слой автокодировщикa:"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Получаем выходы предыдущего слоя\nflatX = Model(input1, first_dense).predict(flatX)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"input2 = Input(shape=(first_dense_l.output_shape[1],))\nsecond_dense_l = Dense(128, activation='tanh', kernel_initializer=kernel_initializer)\nsecond_dense = second_dense_l(input2)\nreverse_second_dense = Dense(256, activation='tanh', kernel_initializer=kernel_initializer)(second_dense)\n\nae_model = Model(input2, reverse_second_dense)\n\ntrain_ae_stack_layer(ae_model, kernel_initializer, optimizer, epochs, flatX)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Склеиваем слои кодирующие,  отбрасываем декодирующие, и получаем нейронную сеть."},{"metadata":{"trusted":true},"cell_type":"code","source":"inputnn = Input(shape=TARGET_SIZE + (3,))\nflatten = Flatten(input_shape=TARGET_SIZE + (3,))(inputnn)\nfirst_dense = first_dense_l(flatten)\nsecond_dense = second_dense_l(first_dense)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Тренируем сеть предварительно настроенную автокодировщиком."},{"metadata":{"trusted":true},"cell_type":"code","source":"kernel_initializer='glorot_uniform'\noptimizer=Adam(learning_rate=0.0001)\nepochs=20\n\noutput = Dense(43, activation='softmax')(second_dense)\nmodel = Model(inputnn, output)\n\ntrain_model(model, kernel_initializer, optimizer, epochs)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Попробуем натренировать все слои автокодировщика одновременно."},{"metadata":{"trusted":true},"cell_type":"code","source":"kernel_initializer='glorot_uniform'\noptimizer=Adam(learning_rate=0.0001)\nepochs=20\n\ninputae = Input(shape=TARGET_SIZE + (3,))\nflatten = Flatten(input_shape=TARGET_SIZE + (3,))(inputae)\nfirst_dense_l = Dense(256, activation='tanh', kernel_initializer=kernel_initializer)\nfirst_dense = first_dense_l(flatten)\nsecond_dense_l = Dense(128, activation='tanh', kernel_initializer=kernel_initializer)\nsecond_dense = second_dense_l(first_dense)\nreverse_second_dense = Dense(256, activation='tanh', kernel_initializer=kernel_initializer)(second_dense)\nreverse_first_dense = Dense(FLATTEN_SIZE, activation='tanh', kernel_initializer=kernel_initializer)(reverse_second_dense)\noutput = Reshape(target_shape = TARGET_SIZE + (3,))(reverse_first_dense)\n\nae_model = Model(inputae, output)\ntrain_autoencoder(ae_model, kernel_initializer, optimizer, epochs)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"flatten = Flatten(input_shape=TARGET_SIZE + (3,))(inputae)\nfirst_dense = first_dense_l(flatten)\nsecond_dense = second_dense_l(first_dense)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"kernel_initializer='glorot_uniform'\noptimizer=Adam(learning_rate=0.0001)\nepochs=20\n\noutput = Dense(43, activation='softmax')(second_dense)\nmodel = Model(inputae, output)\n\ntrain_model(model, kernel_initializer, optimizer, epochs)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Нет никакой выгоды от обучения каждого слоя отдельно. Что соответствует результатам *Is Joint Training Better for Deep Auto-Encoders? Yingbo Zhou, Devansh Arpit, Ifeoma Nwogu, Venu Govindaraju, 2015*"},{"metadata":{},"cell_type":"markdown","source":"Оказывается что, также, нет никакой выгоды от предварительной настройки параметров с помощью автокодировщика."},{"metadata":{},"cell_type":"markdown","source":"Попробуем ещё и свёрточную нейронную сеть. Для обучения такого автокодировщика нам понадобится развёрточный слой Conv2DTranspose. Не будем использовать регуляризацию и послойное обучение."},{"metadata":{"trusted":true},"cell_type":"code","source":"kernel_initializer='glorot_uniform'\noptimizer=Adam(learning_rate=0.0005)\nepochs=20\n\nmodel = tf.keras.models.Sequential([\n    tf.keras.layers.Conv2D(128, (3, 3), activation='relu', input_shape=TARGET_SIZE + (3,)),\n    tf.keras.layers.MaxPooling2D(2, 2),\n    tf.keras.layers.Conv2D(256, (3, 3), activation='relu', input_shape=TARGET_SIZE + (3,)),\n    tf.keras.layers.MaxPooling2D(2, 2),\n    tf.keras.layers.Conv2D(512, (3, 3), activation='relu', input_shape=TARGET_SIZE + (3,)),\n    tf.keras.layers.MaxPooling2D(2, 2),\n    tf.keras.layers.Flatten(),\n    tf.keras.layers.Dense(43, activation='softmax')\n])\n\ntrain_model(model, kernel_initializer, optimizer, epochs)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from keras import backend as K\nfrom tensorflow.keras.layers import Layer\n\n\nclass MaxPoolingWithArgmax2D(Layer):\n    def __init__(self, pool_size=(2, 2), strides=(2, 2), padding='same', **kwargs):\n        super(MaxPoolingWithArgmax2D, self).__init__(**kwargs)\n        self.padding = padding\n        self.pool_size = pool_size\n        self.strides = strides\n\n    def call(self, inputs, **kwargs):\n        padding = self.padding\n        pool_size = self.pool_size\n        strides = self.strides\n        ksize = [1, pool_size[0], pool_size[1], 1]\n        padding = padding.upper()\n        strides = [1, strides[0], strides[1], 1]\n        output, argmax = tf.nn.max_pool_with_argmax(inputs, ksize=ksize, \n                                                    strides=strides, padding=padding,\n                                                    include_batch_in_index=True)\n\n        return [output, argmax]\n\n    def compute_output_shape(self, input_shape):\n        ratio = (1, 2, 2, 1)\n        output_shape = [dim // ratio[idx] if dim is not None else None for idx, dim in enumerate(input_shape)]\n        output_shape = tuple(output_shape)\n        return [output_shape, output_shape]\n\nclass MaxUnpooling2D(Layer):\n    def __init__(self, size=(2, 2), **kwargs):\n        super(MaxUnpooling2D, self).__init__(**kwargs)\n        self.size = size\n\n    def call(self, inputs):\n        pool, ind, prev_tensor = inputs[0], inputs[1], inputs[2]\n        with tf.variable_scope(self.name):\n            input_shape = tf.shape(pool)\n            o_shape = tf.shape(prev_tensor)\n            output_shape = [input_shape[0], o_shape[1], o_shape[2], input_shape[3]]\n            flat_input_size = tf.reduce_prod(input_shape)\n            flat_output_size = tf.reduce_prod(output_shape)\n            \n            upsampled = K.repeat_elements(pool, self.size[0], axis=1)\n            upsampled = K.repeat_elements(upsampled, self.size[1], axis=2)\n            upsampled = tf.reshape(upsampled, [flat_output_size])\n            indices = tf.reshape(ind, [flat_input_size, 1])\n            gathered_updates = tf.gather_nd(upsampled, indices)\n            ret = tf.scatter_nd(indices, gathered_updates, shape=tf.cast([flat_output_size], tf.int64))\n            ret = tf.reshape(ret, output_shape)\n\n            set_input_shape = pool.get_shape()\n            prev_tensor_shape = prev_tensor.get_shape()\n\n            set_output_shape = [set_input_shape[0], prev_tensor_shape[1], prev_tensor_shape[2], set_input_shape[3]]\n            ret.set_shape(set_output_shape)\n\n            return ret\n\n    def compute_output_shape(self, input_shape):\n        inds_shape = input_shape[1]\n        return inds_shape[0], inds_shape[1] * self.size[0], inds_shape[2] * self.size[1], inds_shape[3]\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"inputae = Input(shape=TARGET_SIZE + (3,))\nfirst_conv_l = Conv2D(128, (3, 3), activation='relu')\nfirst_conv = first_conv_l(inputae)\n(first_mp, first_mp_inds) = MaxPoolingWithArgmax2D((2, 2))(first_conv)\nsecond_conv_l = Conv2D(256, (3, 3), activation='relu')\nsecond_conv = second_conv_l(first_mp)\n(second_mp, second_mp_inds) = MaxPoolingWithArgmax2D((2, 2))(second_conv)\nthird_conv_l = Conv2D(512, (3, 3), activation='relu')\nthird_conv = third_conv_l(second_mp)\nthird_mp_l = MaxPoolingWithArgmax2D((2, 2))\n(third_mp, third_mp_inds) = third_mp_l(third_conv)\n\nreverse_third_mp = MaxUnpooling2D((2, 2))((third_mp, third_mp_inds, third_conv))\nreverse_third_conv = Conv2DTranspose(256, (3, 3), activation='relu')(reverse_third_mp)\nreverse_second_mp = MaxUnpooling2D((2, 2))((reverse_third_conv, second_mp_inds, second_conv))\nreverse_second_conv = Conv2DTranspose(128, (3, 3), activation='relu')(reverse_second_mp)\nreverse_first_mp = MaxUnpooling2D((2, 2))((reverse_second_conv, first_mp_inds, first_conv))\nreverse_first_conv = Conv2DTranspose(3, (3, 3), activation='relu')(reverse_first_mp)\noutput = reverse_first_conv","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"kernel_initializer = 'glorot_uniform'\noptimizer=Adam(learning_rate=0.00001)\nepochs=50\n\nae_model = Model(inputae, output)\nae_model.summary()\ntrain_autoencoder(ae_model, kernel_initializer, optimizer, epochs)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"kernel_initializer='glorot_uniform'\noptimizer=Adam(learning_rate=0.0005)\nepochs=20\n\nflatten = Flatten()(third_mp)\noutput = Dense(43, activation='softmax')(flatten)\nmodel = Model(inputae, output)\n\ntrain_model(model, kernel_initializer, optimizer, epochs)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":1}